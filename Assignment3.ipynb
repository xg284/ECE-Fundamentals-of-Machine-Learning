{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality Classification\n",
    "\n",
    "In this assignment, we will use logistic regression to judge the quality of wines. The dataset is taken from UCI machine learning repository. For description of the dataset, see [here](https://archive.ics.uci.edu/ml/datasets/wine+quality).\n",
    "\n",
    "Attributes of the dataset are listed as following:\n",
    "1. fixed acidity \n",
    "2. volatile acidity \n",
    "3. citric acid \n",
    "4. residual sugar \n",
    "5. chlorides \n",
    "6. free sulfur dioxide \n",
    "7. total sulfur dioxide \n",
    "8. density \n",
    "9. pH \n",
    "10. sulphates \n",
    "11. alcohol \n",
    "\n",
    "Output variable (based on sensory data): \n",
    "12. quality (score between 0 and 10)\n",
    "\n",
    "The following code loads the dataset, and the dataset looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4731</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.031</td>\n",
       "      <td>53.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.99321</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.46</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>937</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.58</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.044</td>\n",
       "      <td>42.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1217</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.301</td>\n",
       "      <td>24.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.99930</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3296</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.42</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.044</td>\n",
       "      <td>60.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.99562</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4524</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.049</td>\n",
       "      <td>59.5</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.99500</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.047</td>\n",
       "      <td>42.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.99283</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>785</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>31.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.99815</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>20.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.56</td>\n",
       "      <td>12.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>562</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.27</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.063</td>\n",
       "      <td>39.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.63</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1285</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.026</td>\n",
       "      <td>29.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.99100</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.78</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "4731            5.3              0.31         0.38            10.5      0.031   \n",
       "937             6.1              0.36         0.58            15.0      0.044   \n",
       "1217            8.0              0.61         0.38            12.1      0.301   \n",
       "3296            6.6              0.28         0.42             8.2      0.044   \n",
       "4524            6.6              0.16         0.25             9.8      0.049   \n",
       "3640            6.8              0.19         0.33             4.9      0.047   \n",
       "785             7.6              0.30         0.27            10.6      0.039   \n",
       "393             7.3              0.24         0.43             2.0      0.021   \n",
       "562             7.7              0.34         0.27             8.8      0.063   \n",
       "1285            7.8              0.16         0.41             1.7      0.026   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "4731                 53.0                 140.0  0.99321  3.34       0.46   \n",
       "937                  42.0                 115.0  0.99780  3.15       0.51   \n",
       "1217                 24.0                 220.0  0.99930  2.94       0.48   \n",
       "3296                 60.0                 196.0  0.99562  3.14       0.48   \n",
       "4524                 59.5                 137.0  0.99500  3.16       0.38   \n",
       "3640                 42.0                 130.0  0.99283  3.12       0.56   \n",
       "785                  31.0                 119.0  0.99815  3.27       0.30   \n",
       "393                  20.0                  69.0  0.99000  3.08       0.56   \n",
       "562                  39.0                 184.0  0.99690  3.09       0.63   \n",
       "1285                 29.0                 140.0  0.99100  3.02       0.78   \n",
       "\n",
       "      alcohol  quality  \n",
       "4731     11.7        6  \n",
       "937       9.0        5  \n",
       "1217      9.2        5  \n",
       "3296      9.4        5  \n",
       "4524     10.0        6  \n",
       "3640     11.0        6  \n",
       "785       9.3        6  \n",
       "393      12.2        6  \n",
       "562       9.2        6  \n",
       "1285     12.5        6  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "#train = np.genfromtxt('wine_training1.txt', delimiter=',')\n",
    "red = pd.read_csv('winequality-red.csv')\n",
    "white = pd.read_csv('winequality-white.csv')\n",
    "red = shuffle(red, random_state = 10)\n",
    "white = shuffle(white, random_state = 10)\n",
    "red.head(10)\n",
    "white.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "To get this into a binary classification task. We split the quality into a binary feature *good* or *bad* depending on whether the quality is larger than 6 or not.\n",
    "\n",
    "Next we randomly pick $70\\%$ of the data to be our training set and the remaining for testing for both red and white wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4731     True\n",
       "937     False\n",
       "1217    False\n",
       "3296    False\n",
       "4524     True\n",
       "3640     True\n",
       "785      True\n",
       "393      True\n",
       "562      True\n",
       "1285     True\n",
       "Name: quality, dtype: bool"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_red = red.iloc[:, :-1]\n",
    "y_red = red.iloc[:, -1] >= 6\n",
    "\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_red, y_red, test_size=0.3, random_state = 0)\n",
    "\n",
    "X_white = white.iloc[:, :-1]\n",
    "y_white = white.iloc[:, -1] >= 6\n",
    "X_train_white, X_test_white, y_train_white, y_test_white = train_test_split(X_white, y_white, test_size=0.3, random_state = 0)\n",
    "\n",
    "#y_red.head(10)\n",
    "y_white.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Logistic Regression for Red Wine\n",
    "\n",
    "Using scikit learn, train a Logistic Regression classifier using 'X_trn_red, y_trn_red'. Use the\n",
    "solver sag, which stands for Stochastic Average Gradient. Set max iteration to be 10000. Test the model on X_test_red. Output the testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing error for red wine is: 0.275.\n"
     ]
    }
   ],
   "source": [
    "#========Your code here ======\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clfred = LogisticRegression(random_state=0,solver='sag',max_iter=10000).fit(X_train_red, y_train_red)\n",
    "clfred.predict(X_test_red)\n",
    "error_red=1-clfred.score(X_test_red, y_test_red)\n",
    "\n",
    "#========================\n",
    "print('The testing error for red wine is: ' + str(error_red) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 Logistic Regression for White Wine\n",
    "\n",
    "Using scikit learn, train a Logistic Regression classifier using 'X_trn_white, y_trn_white'. Use the\n",
    "solver sag, which stands for Stochastic Average Gradient. Set max iteration to be 10000. Test the model on X_test_white. Output the testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing error for white wine is: 0.2612244897959184.\n"
     ]
    }
   ],
   "source": [
    "#========Your code here ======\n",
    "clfwhite = LogisticRegression(random_state=0,solver='sag',max_iter=10000).fit(X_train_white, y_train_white)\n",
    "clfwhite.predict(X_test_white)\n",
    "error_white=1-clfwhite.score(X_test_white, y_test_white)\n",
    "\n",
    "\n",
    "#========================\n",
    "print('The testing error for white wine is: ' + str(error_white) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 \n",
    "Use the model you trained using 'X_trn_white, y_trn_white' to test on 'X_test_red' and use the model you trained on 'X_test_white'. Print out the errors and compare with previous results. Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing error for red wine using white wine training data is: 0.35624999999999996.\n",
      "The testing error for white wine using red wine training data is: 0.34013605442176875.\n"
     ]
    }
   ],
   "source": [
    "#========Your code here ======\n",
    "error_red=1-clfwhite.score(X_test_red, y_test_red)\n",
    "error_white=1-clfred.score(X_test_white, y_test_white)\n",
    "\n",
    "#========================\n",
    "print('The testing error for red wine using white wine training data is: ' + str(error_red) + '.')\n",
    "print('The testing error for white wine using red wine training data is: ' + str(error_white) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: Compare with previous results, the errors we got using the model trained with 'X_trn_white, y_trn_white' to test on 'X_test_red'and using the model trained on 'X_test_white'are higher. Using unpair model will result in a higher error, this make sense because the red wine and white wine data are not the same. For instance, the trained model on red wine only give better result when test the data of the same type of wine rather not the other type of wine.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 The effect of regularization\n",
    "Using red wine dataset. Implement logistic regression in sklearn, using $\\ell_2$ regularization with regularizer value C in the set $\\{0.00001 \\times 4^i: i = 0,1,2,..., 15\\}$. (The regularization parameter is 'C' in scikit-learn, which is the inverse of $\\lambda$ we see in class). Plot the training error and test error with respect to the regularizer value. Explain what you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d713a2e508>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = np.array(range(0,15))\n",
    "alpha = 0.00001*(4**N)\n",
    "error_trn = np.zeros(15)\n",
    "error_tst = np.zeros(15)\n",
    "#========Your code here ======\n",
    "for i in range (15):\n",
    "    clfwhite = LogisticRegression(random_state=0,solver='sag',max_iter=10000,C=alpha[i]).fit(X_train_red, y_train_red)\n",
    "    clfwhite.predict(X_test_red)\n",
    "    error_tst[i]=1-clfwhite.score(X_test_red, y_test_red)\n",
    "    error_trn[i]=1-clfwhite.score(X_train_red, y_train_red)\n",
    "\n",
    "\n",
    "#========================\n",
    "plt.figure(1)\n",
    "plt.semilogx(alpha, error_tst,label = 'Test')\n",
    "plt.semilogx(alpha, error_trn, label = 'Train')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: From the plot we can see that both the train error and test error are basically reducing as using ℓ2 regularization with regularizer value C getting larger. From the begining, the test error is lower than train error. However, the test error goes up as C from 10^-4 to 10^-2, especially arround C equal to 10^-2. This happens because overfitting. After that the test error goes lower as train error does, but keeps a littel bit higher than the train error. Also, after C equals to 10^2, both the train error and test error still the same and do not reduce anymore. Therefore, higher regularizer may give a lower error but we nee dto careful with the overfitting, and the error will stay the same after a certain point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
